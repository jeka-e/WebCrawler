{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tld import get_fld\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cross_domain(url1, url2):\n",
    "    return url1 != url2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_dir = '..\\crawl_data_gov'\n",
    "news_dir = '..\\crawl_data_news'\n",
    "ext = 'har'\n",
    "num_get_reqs_gov = 0\n",
    "num_get_reqs_news = 0\n",
    "num_post_reqs_gov = 0\n",
    "num_post_reqs_news = 0\n",
    "num_other_reqs_gov = 0\n",
    "num_other_reqs_news = 0\n",
    "response_codes = [301,308,302,303,307]\n",
    "gov_redirection_pairs = defaultdict(set)\n",
    "news_redirection_pairs = defaultdict(set)\n",
    "\n",
    "for file in os.listdir(gov_dir):\n",
    "    if file.endswith(ext):\n",
    "        with open('..\\crawl_data_gov\\\\' + file, 'r', encoding='utf-8') as har_file:\n",
    "            har_data = json.load(har_file)\n",
    "            entries = har_data['log']['entries']\n",
    "\n",
    "            for entry in entries:\n",
    "                if entry['request']['method'] == \"GET\":\n",
    "                    num_get_reqs_gov += 1\n",
    "                elif entry['request']['method'] == \"POST\":\n",
    "                    num_post_reqs_gov += 1\n",
    "                else:\n",
    "                    num_other_reqs_gov += 1\n",
    "                \n",
    "                if entry['response']['status'] in response_codes:\n",
    "                    source = get_fld(entry['request']['url'])\n",
    "                    target = get_fld(entry['response']['redirectURL'])\n",
    "                    \n",
    "                    if is_cross_domain(source, target):\n",
    "                        gov_redirection_pairs[(source, target)].add(file)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "for file in os.listdir(news_dir):\n",
    "    if file.endswith(ext):\n",
    "        with open('..\\crawl_data_news\\\\' + file, 'r', encoding='utf-8') as har_file:\n",
    "            har_data = json.load(har_file)\n",
    "            entries = har_data['log']['entries']\n",
    "\n",
    "            for entry in entries:\n",
    "                if entry['request']['method'] == \"GET\":\n",
    "                    num_get_reqs_news += 1\n",
    "                elif entry['request']['method'] == \"POST\":\n",
    "                    num_post_reqs_news += 1\n",
    "                else:\n",
    "                    num_other_reqs_news += 1\n",
    "\n",
    "                if entry['response']['status'] in response_codes:\n",
    "                    source = get_fld(entry['request']['url'])\n",
    "                    target = get_fld(entry['response']['redirectURL'])\n",
    "                    \n",
    "                    if is_cross_domain(source, target):\n",
    "                        news_redirection_pairs[(source, target)].add(file)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_pair_counts = {pair: len(websites) for pair, websites in gov_redirection_pairs.items()}\n",
    "gov_most_common_elements = Counter(gov_pair_counts).most_common(3)\n",
    "\n",
    "news_pair_counts = {pair: len(websites) for pair, websites in news_redirection_pairs.items()}\n",
    "news_most_common_elements = Counter(news_pair_counts).most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_2b1c0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_2b1c0_level0_col0\" class=\"col_heading level0 col0\" >HTTP Method</th>\n",
       "      <th id=\"T_2b1c0_level0_col1\" class=\"col_heading level0 col1\" >Crawl-news</th>\n",
       "      <th id=\"T_2b1c0_level0_col2\" class=\"col_heading level0 col2\" >Crawl-gov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_2b1c0_row0_col0\" class=\"data row0 col0\" >GET</td>\n",
       "      <td id=\"T_2b1c0_row0_col1\" class=\"data row0 col1\" >14364 (89.5%)</td>\n",
       "      <td id=\"T_2b1c0_row0_col2\" class=\"data row0 col2\" >1087 (93.5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2b1c0_row1_col0\" class=\"data row1 col0\" >POST</td>\n",
       "      <td id=\"T_2b1c0_row1_col1\" class=\"data row1 col1\" >1677 (10.5%)</td>\n",
       "      <td id=\"T_2b1c0_row1_col2\" class=\"data row1 col2\" >75 (6.5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2b1c0_row2_col0\" class=\"data row2 col0\" >other</td>\n",
       "      <td id=\"T_2b1c0_row2_col1\" class=\"data row2 col1\" >5 (0.0%)</td>\n",
       "      <td id=\"T_2b1c0_row2_col2\" class=\"data row2 col2\" >0 (0.0%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1819eb1ba90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {\n",
    "    'HTTP Method': ['GET', 'POST', 'other'],\n",
    "    'Crawl-news': [num_get_reqs_news, num_post_reqs_news, num_other_reqs_news],\n",
    "    'Crawl-gov': [num_get_reqs_gov, num_post_reqs_gov, num_other_reqs_gov]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "totals = df[['Crawl-gov', 'Crawl-news']].sum()\n",
    "\n",
    "df['Crawl-gov %'] = (df['Crawl-gov'] / totals['Crawl-gov']) * 100\n",
    "df['Crawl-news %'] = (df['Crawl-news'] / totals['Crawl-news']) * 100\n",
    "\n",
    "df['Crawl-gov'] = df['Crawl-gov'].astype(str) + \" (\" + df['Crawl-gov %'].round(1).astype(str) + \"%)\"\n",
    "df['Crawl-news'] = df['Crawl-news'].astype(str) + \" (\" + df['Crawl-news %'].round(1).astype(str) + \"%)\"\n",
    "df = df.drop(columns=['Crawl-gov %', 'Crawl-news %'])\n",
    "\n",
    "display(df.style.hide(axis='index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4b387\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_4b387_level0_col0\" class=\"col_heading level0 col0\" >Source domain</th>\n",
       "      <th id=\"T_4b387_level0_col1\" class=\"col_heading level0 col1\" >Target domain</th>\n",
       "      <th id=\"T_4b387_level0_col2\" class=\"col_heading level0 col2\" >Number of distinct websites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_4b387_row0_col0\" class=\"data row0 col0\" >casalemedia.com</td>\n",
       "      <td id=\"T_4b387_row0_col1\" class=\"data row0 col1\" >doubleclick.net</td>\n",
       "      <td id=\"T_4b387_row0_col2\" class=\"data row0 col2\" >16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4b387_row1_col0\" class=\"data row1 col0\" >doubleclick.net</td>\n",
       "      <td id=\"T_4b387_row1_col1\" class=\"data row1 col1\" >casalemedia.com</td>\n",
       "      <td id=\"T_4b387_row1_col2\" class=\"data row1 col2\" >16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4b387_row2_col0\" class=\"data row2 col0\" >adnxs.com</td>\n",
       "      <td id=\"T_4b387_row2_col1\" class=\"data row2 col1\" >doubleclick.net</td>\n",
       "      <td id=\"T_4b387_row2_col2\" class=\"data row2 col2\" >12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1819ffb89d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data is only available for news websites, since government websites don't have any cross-domain redirections\n",
    "cross_domain_data = {\n",
    "    'Source domain': [news_most_common_elements[0][0][0], news_most_common_elements[1][0][0], news_most_common_elements[2][0][0]],\n",
    "    'Target domain': [news_most_common_elements[0][0][1], news_most_common_elements[1][0][1], news_most_common_elements[2][0][1]],\n",
    "    'Number of distinct websites': [news_most_common_elements[0][1], news_most_common_elements[1][1], news_most_common_elements[2][1]]\n",
    "}\n",
    "cross_domain_df = pd.DataFrame(cross_domain_data)\n",
    "display(cross_domain_df.style.hide(axis='index'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
