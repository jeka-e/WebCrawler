{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from tld import get_fld\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from collections import Counter, defaultdict\n",
    "import dns.resolver\n",
    "import tldextract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - table for most prevalent domains + isTracker\n",
    "def get_tracking_domains_list():\n",
    "    with open('disconnect-tracking-services.json', 'r') as f:\n",
    "        tracking_services = json.load(f)\n",
    "\n",
    "    all_tracker_domains = set()\n",
    "    for category in tracking_services['categories'].values():\n",
    "        for org in category:\n",
    "            for url in org.values():\n",
    "                for domains in url.values():\n",
    "                    all_tracker_domains.update(domains)\n",
    "    return list(all_tracker_domains)\n",
    "\n",
    "TRACKING_DOMAINS = get_tracking_domains_list()\n",
    "GOV_DIR = '../crawl_data_gov'\n",
    "NEWS_DIR = '../crawl_data_news'\n",
    "EXT = 'har'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACT ALL NECESSARY DATA FROM HAR FILES IN ONE ITERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_CODES = [301,308,302,303,307]\n",
    "\n",
    "def get_all_info_from_entries(entries, gov_domain, filename):\n",
    "\t# for 1, 3\n",
    "\tdistinct_third_party_domains = {}\n",
    "\tnum_third_party_requests = 0\n",
    "\n",
    "\t# for 4\n",
    "\tnum_get_reqs = 0\n",
    "\tnum_post_reqs = 0\n",
    "\tnum_other_reqs = 0\n",
    "\n",
    "\t# for 7\n",
    "\taccept_ch_hints = {}\n",
    "\tvisited_hints_in_website = []\n",
    "\n",
    "\t# for 8\n",
    "\tredirection_pairs = defaultdict(set)\n",
    "\n",
    "\t# for 9\n",
    "\tfirst_party_subdomains = set()\n",
    "\n",
    "\tfor entry in entries:\n",
    "\t\t# for 1, 3 \n",
    "\t\tnum_third_party_requests, distinct_third_party_domains = get_third_party_domain_counts(entry, gov_domain, distinct_third_party_domains, num_third_party_requests)\n",
    "\t\t\n",
    "\t\t# for 4\n",
    "\t\tif entry['request']['method'] == \"GET\":\n",
    "\t\t\tnum_get_reqs += 1\n",
    "\t\telif entry['request']['method'] == \"POST\":\n",
    "\t\t\tnum_post_reqs += 1\n",
    "\t\telse:\n",
    "\t\t\tnum_other_reqs += 1\n",
    "\n",
    "\t\t# # 7 - ch header\n",
    "\t\t# accept_ch_hints, visited_hints_in_website = get_accept_ch_header_requests(entry, accept_ch_hints, visited_hints_in_website)\n",
    "\t\t\n",
    "\t\t# # 8 - cross-domain redirections\n",
    "\t\t# if entry['response']['status'] in RESPONSE_CODES:\n",
    "\t\t# \tsource = get_fld(entry['request']['url'])\n",
    "\t\t# \ttarget = get_fld(entry['response']['redirectURL'])\n",
    "\t\t\t\n",
    "\t\t# \tif is_cross_domain(source, target):\n",
    "\t\t# \t\tredirection_pairs[(source, target)].add(filename)\n",
    "\t\t\n",
    "\t\t# # 9 - CNAME\n",
    "\t\t# main_domain = \"ad.nl\"  # TODO  why ? for gov ad.nl,  different for news\n",
    "\t\t# request_url = entry[\"request\"][\"url\"]\n",
    "\t\t# hostname = urlparse(request_url).hostname\n",
    "\t\t# if hostname:\n",
    "\t\t# \tdomain = get_fld(request_url)\n",
    "\t\t# \tif domain == main_domain:\n",
    "\t\t# \t\tfirst_party_subdomains.add(hostname)\n",
    "\n",
    "\treturn num_third_party_requests, distinct_third_party_domains, num_get_reqs, num_post_reqs, num_other_reqs\n",
    "\n",
    "\n",
    "def is_cross_domain(url1, url2):\n",
    "    return url1 != url2\n",
    "\t\n",
    "\t\n",
    "def get_third_party_domain_counts(entry, gov_domain, distinct_third_party_domains, num_third_party_requests):\n",
    "\turl = entry['request']['url']\n",
    "\thostname = urlparse(url).hostname\n",
    "\tif hostname and gov_domain not in hostname:\n",
    "\t\tnum_third_party_requests += 1\n",
    "\t\ttld_1 = get_fld(url)\n",
    "\t\tif tld_1 not in distinct_third_party_domains:\n",
    "\t\t\tdistinct_third_party_domains[tld_1] = 0\n",
    "\t\telse: \n",
    "\t\t\tdistinct_third_party_domains[tld_1] += 1\n",
    "\treturn num_third_party_requests, distinct_third_party_domains\n",
    "\n",
    "\n",
    "def get_accept_ch_header_requests(entry, accept_ch_hints, visited_hints_in_website):\n",
    "\theaders = entry['response']['headers']\n",
    "\tfor header in headers:\n",
    "\t\tif header['name'] == 'accept-ch':\n",
    "\t\t\tclient_hints = header['value'].split(',')\n",
    "\t\t\tfor hint in client_hints:\n",
    "\t\t\t\thint = hint.strip()\n",
    "\t\t\t\tif hint in visited_hints_in_website:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\taccept_ch_hints[hint] = accept_ch_hints.get(hint, 0) + 1\n",
    "\t\t\t\tvisited_hints_in_website.append(hint)\n",
    "\treturn accept_ch_hints, visited_hints_in_website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE BIG FUNC FOR EVERYTHING\n",
    "# gov_dir = '..\\crawl_data_gov'\n",
    "# news_dir = '..\\crawl_data_news'\n",
    "GIV_DIR = '../crawl_data_gov'\n",
    "NEWS_DIR = '../crawl_data_news'\n",
    "EXT = 'har'\n",
    "num_requests_gov = []\n",
    "num_requests_news = []\n",
    "num_third_party_requests_gov = []\t\n",
    "num_third_party_requests_news = []\n",
    "num_third_party_domains_gov = []\n",
    "num_third_party_domains_news = []\n",
    "client_hints_gov = []\n",
    "client_hints_news = []\n",
    "\n",
    "num_get_reqs_gov = 0\n",
    "num_get_reqs_news = 0\n",
    "num_post_reqs_gov = 0\n",
    "num_post_reqs_news = 0\n",
    "num_other_reqs_gov = 0\n",
    "num_other_reqs_news = 0\n",
    "gov_redirection_pairs = defaultdict(set)\n",
    "news_redirection_pairs = defaultdict(set)\n",
    "gov_first_party_subdomains = set()\n",
    "news_first_party_subdomains = set()\n",
    "\n",
    "\n",
    "def get_all_info_form_hars(dir):\n",
    "    all_third_party_entries = {}\n",
    "    for file in os.listdir(dir):\n",
    "        if file.endswith(EXT):\n",
    "            with open(dir + '/' + file, 'r', encoding='utf-8') as har_file:\n",
    "                har_data = json.load(har_file)\n",
    "                entries = har_data['log']['entries']\n",
    "\n",
    "                num_requests = len(entries)\n",
    "                num_requests_gov.append(num_requests)\n",
    "\n",
    "                num_third_party_requests, distinct_third_party_domains, num_get_reqs, num_post_reqs, num_other_reqs = get_all_info_from_entries(entries, file.split('.')[0], file)\n",
    "\n",
    "\n",
    "                # num_third_party_requests, distinct_third_party_domains = get_third_party_domain_counts(entries, file.split('.')[0])\n",
    "                # num_third_party_requests_gov.append(num_third_party_requests)\n",
    "                # num_third_party_domains_gov.append(len(distinct_third_party_domains))\n",
    "\n",
    "                # client_hints = get_accept_ch_header_requests(entries)\n",
    "                # client_hints_gov.append(client_hints)\n",
    "\n",
    "                # 3 - count most prevalent 3rd party domains\n",
    "                # all_third_party_entries_gov = dict(Counter(all_third_party_entries_gov) + Counter(distinct_third_party_domains))                \n",
    "    return num_third_party_requests, distinct_third_party_domains, num_get_reqs, num_post_reqs, num_other_reqs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATS AND VIZUALIZATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - BOXPOTS WITH SOME METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_boxplot(data, title, x_label, y_label, x_ticks=[\"Government\", \"News\"], filename=\"boxplot.png\"):\n",
    "    sns.set(rc={'figure.figsize': (10, 10)})\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    ax = sns.boxplot(data=data)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_xticklabels(x_ticks)\n",
    "    ax.set_ylabel(y_label)\n",
    "    plt.savefig(f'boxplots/{filename}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('crawl_data_gov_times') as f:\n",
    "    times_gov_dict = json.load(f)\n",
    "\n",
    "with open('crawl_data_news_times') as f:\n",
    "    times_news_dict = json.load(f)\n",
    "\n",
    "times_gov_list = [dict_val for dict_val in times_gov_dict.values()]\n",
    "times_news_list = [dict_val for dict_val in times_news_dict.values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplot([num_requests_gov, num_requests_news], \"Number of Requests of Government and News Websites\", \"Website Type\", \"Number of Requests\", filename=\"gov_news_requests.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplot([times_gov_list, times_news_list], \"Loading Time of Government and News Websites\", \"Website Type\", \"Loading Time (s)\", filename=\"gov_news_loading_time.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplot([num_third_party_requests_gov, num_third_party_requests_news], \"Number of Third Party Requests of Government and News Websites\", \"Website Type\", \"Number of Third Party Requests\", filename=\"gov_news_third_party_requests.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplot([num_third_party_domains_gov, num_third_party_domains_news], \"Number of Third Party Domains of Government and News Websites\", \"Website Type\", \"Number of Third Party Domains\", filename=\"gov_news_third_party_domains.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - TABLE WITH MIN MEDIAN MAX FOR THE METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\"loading_time\": [times_gov_list, times_news_list], \"num_requests\": [num_requests_gov, num_requests_news], \"num_third_party_requests\": [num_third_party_requests_gov, num_third_party_requests_news], \"num_third_party_domains\": [num_third_party_domains_gov, num_third_party_domains_news]}\n",
    "for metric, values in metrics.items():\n",
    "    print(f\"Metric: {metric}\")\n",
    "    print('News:')\n",
    "    print(f\"Min: {min(values[1])}\")\n",
    "    print(f\"Median: {sum(values[1]) / len(values[1])}\")\n",
    "    print(f\"Max: {max(values[1])}\")\n",
    "    print('Government:')\n",
    "    print(f\"Min: {min(values[0])}\")\n",
    "    print(f\"Median: {sum(values[0]) / len(values[0])}\")\n",
    "    print(f\"Max: {max(values[0])}\")\n",
    "\n",
    "\n",
    "    # TODO PLEASE MAKE A TABLE IN CODE AS WELL!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Table with prevalent third-party domains and indication whether they are classified as a tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prevalent_tracker_domains_table(third_party_entries):\n",
    "    data = {\n",
    "        'Third-party domain': list(third_party_entries.keys()), \n",
    "        'Number of distinct websites': list(third_party_entries.values()),    \n",
    "    }\n",
    "    table = pd.DataFrame(data)\n",
    "    table = table.sort_values(by=['Number of distinct websites'], ascending=False, ignore_index=True)\n",
    "    table['isTracker'] = table['Third-party domain'].apply(lambda x: True if x in TRACKING_DOMAINS else False)\n",
    "    return table[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_table_news = prevalent_tracker_domains_table(all_third_party_entries_news)\n",
    "tracker_table_news.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_table_gov = prevalent_tracker_domains_table(all_third_party_entries_gov)\n",
    "tracker_table_gov.to_latex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 ACCEPT-CH ANALYSIS TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_client_hints_news = {k: v for k, v in sorted(client_hints_news[0].items(), key=lambda item: item[1], reverse=True)}\n",
    "sorted_client_hints_gov = {k: v for k, v in sorted(client_hints_gov[0].items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# Combine client hints from all websites\n",
    "all_client_hints_gov = {}\n",
    "for hints in client_hints_gov:\n",
    "    for hint, count in hints.items():\n",
    "        all_client_hints_gov[hint] = all_client_hints_gov.get(hint, 0) + count\n",
    "\n",
    "# Sort client hints by count\n",
    "sorted_all_client_hints_gov = {k: v for k, v in sorted(all_client_hints_gov.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "all_client_hints_news = {}\n",
    "for hints in client_hints_news:\n",
    "    for hint, count in hints.items():\n",
    "        all_client_hints_news[hint] = all_client_hints_news.get(hint, 0) + count\n",
    "\n",
    "sorted_all_client_hints_news = {k: v for k, v in sorted(all_client_hints_news.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# Gov and news websites client hints combined\n",
    "all_client_hints = {}\n",
    "for hint, count in sorted_all_client_hints_gov.items():\n",
    "    all_client_hints[hint] = all_client_hints.get(hint, 0) + count\n",
    "\n",
    "for hint, count in sorted_all_client_hints_news.items():\n",
    "    all_client_hints[hint] = all_client_hints.get(hint, 0) + count\n",
    "\n",
    "sorted_all_client_hints = {k: v for k, v in sorted(all_client_hints.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# Get 3 most common client hints\n",
    "top_3_client_hints = list(sorted_all_client_hints.keys())[:3]\n",
    "print(top_3_client_hints)\n",
    "\n",
    "# Get counts for top 3 client hints\n",
    "top_3_client_hints_counts = []\n",
    "counts_gov = {}\n",
    "counts_news = {}\n",
    "for hint in top_3_client_hints: \n",
    "    counts_gov[hint] = sorted_all_client_hints_gov.get(hint, 0)\n",
    "    counts_news[hint] = sorted_all_client_hints_news.get(hint, 0)\n",
    "print(counts_gov)\n",
    "print(counts_news)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18d786a7e5bef1edc9c290e74b0843b8b0a408963e1315e985c163de81dec61e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
